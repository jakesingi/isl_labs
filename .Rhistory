getwd()
?runif
runif(1, min = 2, max = 4)
runif(1, min = 2, max = 4)
runif(1, min = 2, max = 4)
install.packages("devtools")
c(1,4)
library(learnr)
?qt
qt(.05/2, 174)
x=rnorm(100)
y=rnorm(100)
plot(x,y)
y=x
y
x
f=outer(x,y,function(x,y)cos(y)/(1+x^2))
contour(x, y, f)
aslkjfdkl
x=1:10
y=x
x
y
f=outer(x,y,function(x,y)cos(y)/(1+x^2))
f
contour(x, y, f)
contour(x, y, f, nlevels=45, add=T)
fa=(f-t(f))/2
countour(x,y,fa,nlevels=15)
contour(x,y,fa,nlevels=15)
image(x,y,fa)
persp(x,y,fa)
persp(x,y,fa,theta=30)
persp(x,y,fa,theta=30,phi=20)
persp(x,y,fa,theta=30,phi=40)
Auto
q()
install.packages(c('ISLR', 'MASS'))
getwd()
setwd('./projects/personal/ISL/labs/')
ls()
library(ISLR)
library(MASS)
library(ISLR)
fix(Boston)
head(Boston)
fix(Boston)
?fix()
print(head(Boston))
print(names(Boston))
# regression: predict median house value for Boston neighborhoods
lm.fit=lm(medv~lstat, data=Boston)  # lstat is the percentage of households with low socioeconomic status
?attach
# regression: predict median house value for Boston neighborhoods
lm.fit=lm(medv~lstat, data=Boston)  # lstat is the percentage of households with low socioeconomic status
attach(Boston)  # attaches data frame to current environment
lm.fit=lm(medv~lstat)
summary(lm.fit)
names(lm.fit)
coef(lm.fit)
names(lm.fit)
coef(lm.fit)
names(lm.fit)
coef(lm.fit)
confint(lm.fit)  # 95% confidence interval for coefficient estimates
data.frame(lstat=(c(5, 10, 15)))
# prediction intervals of medv for various values lstat
predict(lm.fit, data.frame(lstat=(c(5, 10, 15))), interval='prediction')
# plotting the variables and the least squares regression line
plot(lstat, medv)
abline(lm.fit)
# random plotting testing
abline(lm.fit, lwd=3)
# random plotting testing
plot.new
# random plotting testing
abline(lm.fit, lwd=3)
# random plotting testing
abline(lm.fit, lwd=3)
# random plotting testing
abline(lm.fit, lwd=3)
# plotting the variables and the least squares regression line
plot(lstat, medv)
abline(lm.fit)
# random plotting testing
abline(lm.fit, lwd=3)
abline(lm.fit, lwd=3, col='red')
# plotting the variables and the least squares regression line
plot(lstat, medv)
abline(lm.fit)
# random plotting testing
abline(lm.fit, lwd=3)
abline(lm.fit, lwd=3, col='red')
plot(lstat, medv, col="red")
plot(lstat, medv, pch=20)
plot(lstat, medv, pch="+")
plot(1:20, 1:20, pch=1:20)
# diagnostic plots
par(mfrow=c(2, 2))
# diagnostic plots
par(mfrow=c(2, 2))
plot(lm.fit)
# or...
plot(predict(lm.fit), residuals(lm.fit))
plot(predict(lm.fit), rstudent(lm.fit))
plot(hatvalues(lm.fit))
?hatvalues
whic.max(hatvalues(lm.fit))
plot(hatvalues(lm.fit))
whic.max(hatvalues(lm.fit))
plot(hatvalues(lm.fit))
which.max(hatvalues(lm.fit))
lm.fit = lm(medv~lstat+age, data=Boston)
summary(lm.fit)
lm.fit=lm(medv~., data=Boston)
sumarry(lm.fit)
lm.fit=lm(medv~., data=Boston)
summary(lm.fit)
summary(lm.fit)$sigma
summary(lm.fit)$r.sq
install.packages('car')
library(car)
vif(lm.fit)
# going back to age's high p-value noted earlier, let's run a regression excluding it
lm.fit1 = lm(medv~.-age, data=Boston)
summary(lm.fit1)
summary(lm(medv~lstat*age, data=Boston))  # includes lstat, age, and lstat*age as predictors
# regress medv onto lstat and lstat^2
lm.fit2 = lm(medv~lstat+I(lstat^2))
summary(lm.fit2)
# use anova function to analyze difference
lm.fit = lm(medv~lstat)
anova(lm.fit, lm.fit2)
par(mfrow=c(2,2))
plot(lm.fit2)
# higher order polynomial syntax, fifth degree
lm.fit5 = lm(medv~poly(lstat, 5))
summary(lm.fit5)
# log transformation
summary(lm(medv~log(rm), data=Boston))
# Using the Carsets dataset to predict child car seat Sales in 400 locations based on various predictors
fix(Carseats)
# Using the Carsets dataset to predict child car seat Sales in 400 locations based on various predictors
names(Carseats)
Carseats$ShelveLoc
# see that R generates dummy variabels automatically
lm.fit = lm(Sales~.+Income:Advertising+Price:Age, data=Carseats)
summary(lm.fit)
contrasts(ShelveLoc)
contrasts(Carseats$ShelveLoc)
source('~/.active-rstudio-document', echo=TRUE)
